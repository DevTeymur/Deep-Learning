{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7bb16bf",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f1a835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, LSTM, Dropout, BatchNormalization, Dense, GlobalAveragePooling1D, TimeDistributed, MaxPooling1D, Flatten\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from parse_data import load_intra_train, load_intra_test, load_cross_train, load_cross_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137313f",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f296ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSAMPLING_STEP = 8\n",
    "NUM_CLASSES = 4\n",
    "BATCH_SIZE = 3\n",
    "\n",
    "ENCODE_MAP = {\n",
    "        'rest': 0,\n",
    "        'motor': 1,\n",
    "        'memory': 2,\n",
    "        'math': 3,\n",
    "    }\n",
    "\n",
    "INTRA_OR_CROSS_MODE = \"cross\"\n",
    "\n",
    "if INTRA_OR_CROSS_MODE == \"cross\":\n",
    "    load_train = load_cross_train\n",
    "    load_test = load_cross_test\n",
    "elif INTRA_OR_CROSS_MODE == \"intra\":\n",
    "    load_train = load_intra_train\n",
    "    load_test = load_intra_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a48b5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8771e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape from C:\\Users\\guill\\Desktop\\Uni\\DeepLearning\\Final Project data\\Cross\\train: (94976, 3, 248)\n"
     ]
    }
   ],
   "source": [
    "filenamepath_train = (\"C:/Users/guill/Desktop/Uni/DeepLearning/Final Project data/Cross/train\")\n",
    "filenamepath_test = (\"C:/Users/guill/Desktop/Uni/DeepLearning/Final Project data/Cross\")\n",
    "\n",
    "X_train, y_train = load_cross_train(folder_path=filenamepath_train,batch_size=BATCH_SIZE,downsample_step=DOWNSAMPLING_STEP,logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e491ab1b",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b95bbd-ca1a-4155-84b9-c7ba46c98fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining model\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"Defining model\")\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=248, model_dim=64, num_heads=4, num_layers=2, num_classes=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.input_fc = nn.Linear(input_dim, model_dim)\n",
    "        self.pos_encoder = PositionalEncoding(model_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(model_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_fc(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2238c066-f752-4f4d-856f-406861b21e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in dataloader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dataloader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            predicted = torch.argmax(preds, dim=1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(yb.cpu().numpy())\n",
    "    acc = np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "    return acc, all_preds, all_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75375aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter training\n",
      "Epoch 1: Train Loss = 1.3901, Val Accuracy = 0.2500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Enter training\")\n",
    "\n",
    "X_train_np, X_val_np, y_train_np, y_val_np = train_test_split(\n",
    "    np.array(X_train), np.array(y_train), test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val_np, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_np, dtype=torch.long)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=8)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TransformerClassifier(input_dim=X_train_tensor.shape[2]).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, factor=0.5)\n",
    "\n",
    "best_val_acc = 0\n",
    "best_train_loss = 1000\n",
    "best_model_state = None\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model(model, train_loader, criterion, optimizer, device)\n",
    "    val_acc, _, _ = evaluate_model(model, val_loader, device)\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Accuracy = {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc or (val_acc == best_val_acc and train_loss < best_train_loss):\n",
    "        best_val_acc = val_acc\n",
    "        best_train_loss = train_loss\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"\\nâœ… Restored best model with Val Accuracy = {best_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd5d47",
   "metadata": {},
   "source": [
    "# Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84422ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim((0,1))\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa4b76a",
   "metadata": {},
   "source": [
    "# Testing & Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f209ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess test data\n",
    "X_test, y_test = load_cross_test(folder_path=filenamepath_test,batch_size=BATCH_SIZE,downsample_step=DOWNSAMPLING_STEP,logs=1)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe67f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(0.715900182723999, [14, 100000, 0.00015, 0.98]), (0.7168548107147217, [12, 100000, 5e-05, 0.96]), (0.7189745903015137, [13, 100000, 5e-05, 0.92]), (0.7205188870429993, [14, 100000, 0.00015, 0.94]), (0.7219367623329163, [13, 100000, 5e-05, 0.98]), (0.7224982976913452, [14, 100000, 5e-05, 0.98]), (0.7247023582458496, [14, 100000, 0.0001, 0.94]), (0.7249410152435303, [13, 100000, 0.0001, 0.98]), (0.7268081903457642, [13, 100000, 5e-05, 0.94]), (0.7303038239479065, [14, 100000, 5e-05, 0.92]), (0.7378144860267639, [12, 100000, 0.00015, 0.98])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "test_loss, test_acc = lstm_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This piece of code collects all the instances that were predicted as 'motor' by the model in this notebook.\n",
    "# Purpose: Since this model could improve on distinguishing motor and math, we could feed all predictions of 'motor' to a new model, for a second opinion\n",
    "# So this code determines on what instances to ask a second opinion\n",
    "X_second_op = []\n",
    "\n",
    "counter = 0\n",
    "while counter < len(y_test):\n",
    "    if (list(y_test[counter])) == [0.0, 1.0, 0.0, 0.0]:\n",
    "        # feed to other model\n",
    "        instance = (X_test[counter])\n",
    "        \n",
    "        X_second_op.append(instance)\n",
    "\n",
    "    counter = counter + 1\n",
    "\n",
    "X_second_op = np.asarray(X_second_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"rest\", \"motor\", \"memory\", \"math\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89efcef-2ced-4f7f-b8fb-4793470ffa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "refined_accuracy = accuracy_score(y_true, refined_preds)\n",
    "print(f\"Test accuracy after refinement: {refined_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd1d89-c13d-4099-bc47-dbbe1b492464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
