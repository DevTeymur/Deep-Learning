{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7bb16bf",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f1a835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, LSTM, Dropout, BatchNormalization, Dense, GlobalAveragePooling1D, TimeDistributed, MaxPooling1D, Flatten\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from parse_data import load_intra_train, load_intra_test, load_cross_train, load_cross_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137313f",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5f296ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSAMPLING_STEP = 8\n",
    "NUM_CLASSES = 4\n",
    "BATCH_SIZE = 3\n",
    "\n",
    "ENCODE_MAP = {\n",
    "        'rest': 0,\n",
    "        'motor': 1,\n",
    "        'memory': 2,\n",
    "        'math': 3,\n",
    "    }\n",
    "\n",
    "INTRA_OR_CROSS_MODE = \"cross\"\n",
    "\n",
    "if INTRA_OR_CROSS_MODE == \"cross\":\n",
    "    load_train = load_cross_train\n",
    "    load_test = load_cross_test\n",
    "elif INTRA_OR_CROSS_MODE == \"intra\":\n",
    "    load_train = load_intra_train\n",
    "    load_test = load_intra_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a48b5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8771e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape from Data\\Cross\\train: (94976, 3, 248)\n"
     ]
    }
   ],
   "source": [
    "filenamepath = (\"C:/Users/Collin/Documents/Universiteit Utrecht/Periode 4/Deep learning/Project assignment/Final Project data/Final Project data/Intra/train/\")\n",
    "\n",
    "X_train, y_train = load_train(batch_size=BATCH_SIZE,downsample_step=DOWNSAMPLING_STEP,logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e491ab1b",
   "metadata": {},
   "source": [
    "## LSTM Model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b8c0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from test1\n",
      "X.shape from Data\\Cross\\test1: (23744, 3, 248)\n",
      "Loading from test2\n",
      "X.shape from Data\\Cross\\test2: (23744, 3, 248)\n",
      "Loading from test3\n",
      "X.shape from Data\\Cross\\test3: (23744, 3, 248)\n"
     ]
    }
   ],
   "source": [
    "time_steps = X_train.shape[1]\n",
    "num_channels = X_train.shape[2]\n",
    "\n",
    "if y_train.ndim == 1:\n",
    "    y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',#'val_accuracy',#\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Load and preprocess test data\n",
    "X_test, y_test = load_test(batch_size=BATCH_SIZE,downsample_step=DOWNSAMPLING_STEP,logs=1)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_test = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "\n",
    "def run_model(learningrate, decaysteps, decayrate, epochs, batchsize):\n",
    "    lstm_model = Sequential([\n",
    "        TimeDistributed(Dense(16, kernel_regularizer=l2(1e-4)), input_shape=(time_steps, num_channels)),\n",
    "\n",
    "        LSTM(16, return_sequences=True, kernel_regularizer=l2(1e-4)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        LSTM(16, kernel_regularizer=l2(1e-3)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(16, activation='relu', kernel_regularizer=l2(1e-4)),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    lstm_model.compile(optimizer=Nadam(ExponentialDecay(\n",
    "        initial_learning_rate=learningrate,\n",
    "        decay_steps=decaysteps,\n",
    "        decay_rate=decayrate)),#0.94\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    history = lstm_model.fit(\n",
    "        X_train, y_train,   \n",
    "        epochs=epochs,\n",
    "        batch_size=batchsize,#beste tot nu toe: 64,\n",
    "        validation_split=0.5,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "    # Evaluate\n",
    "    test_loss, test_acc = lstm_model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_accuracy = test_acc\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca5fc07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792\n",
      "0.01\n",
      "100\n",
      "0.8\n",
      "4\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "learning_rates = [0.1,0.05,0.01,0.008]\n",
    "decay_steps = [14,24,100,1000]\n",
    "decay_rates = [0.2,0.5,0.8,0.9]\n",
    "epochs = [2,4,6,8,10,12,14]\n",
    "batch_sizes = [6,32,64,128]\n",
    "\n",
    "\n",
    "all_possible_combinations = list(itertools.product(learning_rates, decay_steps, decay_rates, epochs, batch_sizes))\n",
    "print(len(all_possible_combinations))\n",
    "\n",
    "lengte = (len(all_possible_combinations))\n",
    "previous_accuracy = 0.72\n",
    "#0.01 100 0.8 8 32\n",
    "best_lr = 0.008\n",
    "best_ds = 100\n",
    "best_dr = 0.8\n",
    "best_ep = 8\n",
    "best_bs = 32\n",
    "\n",
    "for rate in learning_rates:\n",
    "    accuracy1 = (run_model(learningrate=rate, decaysteps=best_ds, decayrate=best_dr, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy2 = (run_model(learningrate=rate, decaysteps=best_ds, decayrate=best_dr, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy3 = (run_model(learningrate=rate, decaysteps=best_ds, decayrate=best_dr, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy = (accuracy1+accuracy2+accuracy3)/3\n",
    "    if accuracy > previous_accuracy:\n",
    "        previous_accuracy = accuracy\n",
    "        best_lr = rate\n",
    "print(best_lr)\n",
    "for rate in decay_steps:\n",
    "    accuracy1 = (run_model(learningrate=best_lr, decaysteps=rate, decayrate=best_dr, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy2 = (run_model(learningrate=best_lr, decaysteps=rate, decayrate=best_dr, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy3 = (run_model(learningrate=best_lr, decaysteps=rate, decayrate=best_dr, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy = (accuracy1+accuracy2+accuracy3)/3\n",
    "    if accuracy > previous_accuracy:\n",
    "        previous_accuracy = accuracy\n",
    "        best_ds = rate    \n",
    "print(best_ds)    \n",
    "for rate in decay_rates:\n",
    "    accuracy1 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=rate, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy2 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=rate, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy3 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=rate, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy = (accuracy1+accuracy2+accuracy3)/3\n",
    "    if accuracy > previous_accuracy:\n",
    "        previous_accuracy = accuracy\n",
    "        best_dr = rate    \n",
    "print(best_dr)\n",
    "for rate in epochs:\n",
    "    accuracy1 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=best_dr, epochs=rate, batchsize=best_bs))\n",
    "    accuracy2 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=best_dr, epochs=rate, batchsize=best_bs))\n",
    "    accuracy3 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=best_dr, epochs=rate, batchsize=best_bs))\n",
    "    accuracy = (accuracy1+accuracy2+accuracy3)/3\n",
    "    if accuracy > previous_accuracy:\n",
    "        previous_accuracy = accuracy\n",
    "        best_ep = rate    \n",
    "print(best_ep)\n",
    "for rate in batch_sizes:\n",
    "    accuracy1 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=best_dr, epochs=best_ep, batchsize=rate))\n",
    "    accuracy2 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=best_dr, epochs=best_ep, batchsize=rate))\n",
    "    accuracy3 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=best_dr, epochs=best_ep, batchsize=rate))\n",
    "    accuracy = (accuracy1+accuracy2+accuracy3)/3\n",
    "    if accuracy > previous_accuracy:\n",
    "        previous_accuracy = accuracy\n",
    "        best_bs = rate    \n",
    "print(best_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f957d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "0.01\n",
      "105\n",
      "0.8\n",
      "6\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# Fine tuning last bits\n",
    "\n",
    "learning_rates = [0.01]\n",
    "decay_steps = [90,95,100,105]\n",
    "decay_rates = [0.8]\n",
    "epochs = [4,5,6,7,8]\n",
    "batch_sizes = [18,32,64]\n",
    "\n",
    "\n",
    "all_possible_combinations = list(itertools.product(learning_rates, decay_steps, decay_rates, epochs, batch_sizes))\n",
    "print(len(all_possible_combinations))\n",
    "\n",
    "lengte = (len(all_possible_combinations))\n",
    "previous_accuracy = 0.72\n",
    "#0.01 100 0.8 8 32\n",
    "best_lr = 0.01\n",
    "best_ds = 100\n",
    "best_dr = 0.8\n",
    "best_ep = 8\n",
    "best_bs = 32\n",
    "\n",
    "\n",
    "print(best_lr)\n",
    "for rate in decay_steps:\n",
    "    accuracy1 = (run_model(learningrate=best_lr, decaysteps=rate, decayrate=best_dr, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy2 = (run_model(learningrate=best_lr, decaysteps=rate, decayrate=best_dr, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy3 = (run_model(learningrate=best_lr, decaysteps=rate, decayrate=best_dr, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy = (accuracy1+accuracy2+accuracy3)/3\n",
    "    if accuracy > previous_accuracy:\n",
    "        previous_accuracy = accuracy\n",
    "        best_ds = rate    \n",
    "print(best_ds)    \n",
    "for rate in decay_rates:\n",
    "    accuracy1 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=rate, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy2 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=rate, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy3 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=rate, epochs=best_ep, batchsize=best_bs))\n",
    "    accuracy = (accuracy1+accuracy2+accuracy3)/3\n",
    "    if accuracy > previous_accuracy:\n",
    "        previous_accuracy = accuracy\n",
    "        best_dr = rate    \n",
    "print(best_dr)\n",
    "for rate in epochs:\n",
    "    accuracy1 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=best_dr, epochs=rate, batchsize=best_bs))\n",
    "    accuracy2 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=best_dr, epochs=rate, batchsize=best_bs))\n",
    "    accuracy3 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=best_dr, epochs=rate, batchsize=best_bs))\n",
    "    accuracy = (accuracy1+accuracy2+accuracy3)/3\n",
    "    if accuracy > previous_accuracy:\n",
    "        previous_accuracy = accuracy\n",
    "        best_ep = rate    \n",
    "print(best_ep)\n",
    "for rate in batch_sizes:\n",
    "    accuracy1 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=best_dr, epochs=best_ep, batchsize=rate))\n",
    "    accuracy2 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=best_dr, epochs=best_ep, batchsize=rate))\n",
    "    accuracy3 = (run_model(learningrate=best_lr, decaysteps=best_ds, decayrate=best_dr, epochs=best_ep, batchsize=rate))\n",
    "    accuracy = (accuracy1+accuracy2+accuracy3)/3\n",
    "    if accuracy > previous_accuracy:\n",
    "        previous_accuracy = accuracy\n",
    "        best_bs = rate    \n",
    "print(best_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54a09c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy:  0.7340895533561707\n",
      "0.01 105 0.8 6 32\n"
     ]
    }
   ],
   "source": [
    "print(\"best accuracy: \", previous_accuracy)\n",
    "print(best_lr,\n",
    "best_ds,\n",
    "best_dr,\n",
    "best_ep,\n",
    "best_bs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
