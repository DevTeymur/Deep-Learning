{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7bb16bf",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, LSTM, Dropout, BatchNormalization, Dense, GlobalAveragePooling1D\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137313f",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f296ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSAMPLING_STEP = 4\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "ENCODE_MAP = {\n",
    "        'rest': 0,\n",
    "        'motor': 1,\n",
    "        'memory': 2,\n",
    "        'math': 3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a48b5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f16469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(filename_with_dir):\n",
    "    filename_without_dir = filename_with_dir.split('/')[-1]\n",
    "    temp = filename_without_dir.split('_')[:-1]\n",
    "    dataset_name = '_'.join(temp)\n",
    "    return dataset_name\n",
    "\n",
    "def extract_label(filename, logs=False, encode_mapping=ENCODE_MAP):\n",
    "    for key in encode_mapping:\n",
    "        if key in filename:\n",
    "            if logs: print(f\"Mapping label {filename} to {encode_mapping[key]}\")\n",
    "            return encode_mapping[key]\n",
    "    return encode_mapping['math']\n",
    "\n",
    "\n",
    "def load_all_data(folder_path, logs=False):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.h5'):\n",
    "            print(f\"Loading {filename}...\") if logs else None\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                dataset_name = get_dataset_name(file_path)\n",
    "                data = f.get(dataset_name)[()]\n",
    "                label = extract_label(filename)\n",
    "                print(f\"Data shape: {data.shape}, label: {label}\") if logs else None\n",
    "                print(\"_____\"*10)\n",
    "                X.append(data)       # shape (248, 35624)\n",
    "                y.append(label)      # 'motor', 'rest', etc.\n",
    "    X = np.array(X)  # shape (n_samples, 248, 35624)\n",
    "    y = np.array(y)  # shape (n_samples,)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e9b78f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a48c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalize(data):\n",
    "    # data: shape (248, T)\n",
    "    mean = np.mean(data, axis=1, keepdims=True)\n",
    "    std = np.std(data, axis=1, keepdims=True) + 1e-8\n",
    "    return (data - mean) / std\n",
    "\n",
    "\n",
    "def downsample(data, step=DOWNSAMPLING_STEP):\n",
    "    # data: shape (248, T)\n",
    "    return np.array(data[:, ::step])  # keep every 8th column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9544501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder name and load the data. (Don't push data folders to GitHub!!!)\n",
    "X_train, y_train = load_all_data(\"Intra/train\", logs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d473a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape before preprocessing {np.array(X_train).shape}\")  # 3D array: (n_samples, n_channels, n_times)\n",
    "print(y_train)\n",
    "X_train = [downsample(z_score_normalize(x)) for x in X_train]\n",
    "X_train = np.array(X_train)  # shape (n_samples, n_channels, n_times)\n",
    "print(f\"X_train shape after preprocessing {np.array(X_train).shape}\")  # 3D array: (n_samples, n_channels, n_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e491ab1b",
   "metadata": {},
   "source": [
    "## LSTM Model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = X_train.shape[1]\n",
    "num_channels = X_train.shape[2]\n",
    "\n",
    "\n",
    "if y_train.ndim == 1:\n",
    "    y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "print(y_train.shape)\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Define LSTM model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(128, input_shape=(time_steps, num_channels), return_sequences=True),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    LSTM(64),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer=Nadam(learning_rate=0.001),\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75375aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lstm_model.fit(\n",
    "    X_train, y_train,   \n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa4b76a",
   "metadata": {},
   "source": [
    "## Testing and evaluating part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f209ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess test data\n",
    "X_test, y_test = load_all_data(\"Intra/test\", logs=0)\n",
    "print(f\"X_test shape before preprocessing: {np.array(X_test).shape}\")\n",
    "\n",
    "X_test = [downsample(z_score_normalize(x), step=4) for x in X_test]\n",
    "X_test = np.array(X_test)\n",
    "print(f\"X_test shape after preprocessing: {np.array(X_test).shape}\")\n",
    "\n",
    "# One-hot encode labels\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "test_loss, test_acc = lstm_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84422ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "y_pred_probs = lstm_model.predict(X_test)\n",
    "# Convert one-hot back to class labels\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"rest\", \"motor\", \"memory\", \"math\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c680901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
